{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pandas_L1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMWKS2SGnFiRtHN/k8JKU3x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GezhinOleg/Num_Pnd_L2/blob/main/pandas_L1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afrJpwJhX_ql"
      },
      "source": [
        "Задание 1\n",
        "Скачайте с сайта grouplens.org...movielens/ датасет\n",
        "любого размера. Определите какому фильму было\n",
        "выставлено больше всего оценок 5.0.\n",
        "\n",
        "Задание 2\n",
        "По данным файла power.csv посчитайте суммарное\n",
        "потребление стран Прибалтики (Латвия, Литва и Эстония)\n",
        "категорий 4, 12 и 21 за период с 2005 по 2010 года.\n",
        "Не учитывайте в расчетах отрицательные значения quantity.ml_25m\n",
        "\n",
        "Задание 3\n",
        "Выберите страницу любого сайта с табличными данными.\n",
        "Импортируйте таблицы в pandas dataframe.\n",
        "Примеры страниц (необязательно брать именно эти):\n",
        "https://fortrader.org/quotes\n",
        "www.finanz.ru...om-vremeni"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SLVzp1qYBT0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lDgtTWJYG-N"
      },
      "source": [
        "ratings = pd.read_csv('ml_25m/ratings.csv')\n",
        "rating_modified = ratings.set_index('userId')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egvMsau3YPBG"
      },
      "source": [
        "Первое задание"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG4NI-35YTgE"
      },
      "source": [
        "otbor = ratings.loc[ratings['rating'] == 5.0]\n",
        "otbor.movieId.value_counts().head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2wTia6KZNyv"
      },
      "source": [
        "powers = pd.read_csv('ml_25m/power.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u12V7EQ4ZYNl"
      },
      "source": [
        "Второе задание"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "471V-GIsZdUn"
      },
      "source": [
        "first_filter = powers[ (powers['country']=='Lithuania') | (powers['country']=='Latvia') | (powers['country']=='Estonia') ]\n",
        "second_filter = first_filter[ (first_filter['category'] == 4) | (first_filter['category'] == 12) | (first_filter['category'] == 21) ]\n",
        "third_filter = second_filter.loc[(second_filter['year'] < 2010) & (second_filter['year'] > 2005) & (second_filter['quantity'] > 0)] \n",
        "# third_filter.head()\n",
        "third_filter['quantity'].sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIpRx5wZZgPi"
      },
      "source": [
        "Была мысль объеденить все в один запрос через & и |, но в процессе запутался в скобках и знаках, поэтому решил оставить так."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HHhFcikZzE0"
      },
      "source": [
        "page_url = 'https://www.finanz.ru/valyuty/v-realnom-vremeni'\n",
        "\n",
        "# Импортируем нужную нам страницу в df\n",
        "# attrs = {'class': 'news_table'} ---> указываем какой именно блок нам нужен\n",
        "# encoding='utf-8' ---> указываем кодировку страниц для корректного отображения кириллицы\n",
        "df = pd.read_html(page_url, attrs = {'class': 'quote_list'}, encoding='utf-8')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}